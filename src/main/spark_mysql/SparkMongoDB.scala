package spark_mysql

object SparkMongoDB {
    def main(args: Array[String]): Unit = {

//        val readConfig = ReadConfig(Map("collection" -> "spark", "readPreference.name" -> "secondaryPreferred"), Some(ReadConfig(sc)))
//        val customRdd = MongoSpark.load(sc, readConfig)
//        println(customRdd.count)
//        println(customRdd.first.toJson)
    }
}
